<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <title>ç°¡æ˜“ç‰ˆ MediaPipe äººè‡‰ç‰¹æ•ˆ</title>
    <style>
        body {
            margin: 0;
            padding: 20px;
            font-family: Arial, sans-serif;
        }
        #container {
            position: relative;
            width: 1280px;
            height: 720px;
        }
        #webcam {
            position: absolute;
            width: 1280px;
            height: 720px;
            transform: rotateY(180deg);
        }
        #output_canvas {
            position: absolute;
            width: 1280px;
            height: 720px;
            transform: rotateY(180deg);
        }
        #status {
            position: fixed;
            top: 10px;
            left: 10px;
            background: rgba(0,0,0,0.7);
            color: white;
            padding: 10px;
            border-radius: 5px;
            z-index: 1000;
        }
        /* æ–°å¢æ˜Ÿæ˜Ÿçš„æ¨£å¼ */
        .star {
            position: absolute;
            font-size: 24px;
            pointer-events: none;
            z-index: 100;
            transition: transform 0.2s;
        }
        .star:hover {
            transform: scale(1.2);
        }
    </style>
</head>
<body>
    <div id="status">ç³»çµ±ç‹€æ…‹: åˆå§‹åŒ–ä¸­...</div>
    <div id="container">
        <video id="webcam" autoplay></video>
        <canvas id="output_canvas"></canvas>
    </div>

<script type="module">
import vision from "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.3";
const { FaceLandmarker, FilesetResolver, DrawingUtils } = vision;

const statusDiv = document.getElementById('status');
const video = document.getElementById('webcam');
const canvasElement = document.getElementById('output_canvas');
const canvasCtx = canvasElement.getContext('2d');

let faceLandmarker;
let webcamRunning = false;
let lastVideoTime = -1;
let results = undefined;

// æ–°å¢æ˜Ÿæ˜Ÿç›¸é—œè®Šæ•¸
let stars = [];
let lastStarTime = 0;
const STAR_INTERVAL = 50; // æ¯50msç”¢ç”Ÿä¸€é¡†æ˜Ÿæ˜Ÿ
const GRAVITY = 0.4; // é‡åŠ›åŠ é€Ÿåº¦
const INITIAL_VELOCITY = 10; // åˆå§‹é€Ÿåº¦

// æ˜Ÿæ˜Ÿé¡åˆ¥
class Star {
    constructor(x, y) {
        this.element = document.createElement('div');
        this.element.className = 'star';
        this.element.textContent = 'â­';
        this.element.style.left = x + 'px';
        this.element.style.top = y + 'px';
        this.element.style.transform = 'scale(0.5)';
        document.body.appendChild(this.element);

        this.x = x;
        this.y = y;
        this.vx = (Math.random() - 0.5) * INITIAL_VELOCITY * 2;
        this.vy = -INITIAL_VELOCITY * (1 + Math.random());
        this.opacity = 1;
        this.age = 0;
    }

    update() {
        this.age++;
        this.x += this.vx;
        this.vy += GRAVITY;
        this.y += this.vy;
        this.opacity = Math.max(0, 1 - this.age / 40);

        this.element.style.left = this.x + 'px';
        this.element.style.top = this.y + 'px';
        this.element.style.opacity = this.opacity;

        return this.opacity > 0;
    }

    remove() {
        this.element.remove();
    }
}

// è¨­å®šç‹€æ…‹é¡¯ç¤º
function setStatus(message) {
    statusDiv.textContent = `ç³»çµ±ç‹€æ…‹: ${message}`;
}

// åˆå§‹åŒ– FaceLandmarker
async function initializeFaceLandmarker() {
    try {
        setStatus("è¼‰å…¥æ¨¡å‹ä¸­...");
        const filesetResolver = await FilesetResolver.forVisionTasks(
            "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.3/wasm"
        );
        
        faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {
            baseOptions: {
                modelAssetPath: `https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`,
                delegate: "GPU"
            },
            outputFaceBlendshapes: true,
            runningMode: "VIDEO",
            numFaces: 1
        });
        
        setStatus("æ¨¡å‹è¼‰å…¥å®Œæˆï¼Œå•Ÿå‹•æ”å½±æ©Ÿ...");
        startCamera();
    } catch (error) {
        setStatus(`éŒ¯èª¤: ${error.message}`);
        console.error(error);
    }
}

// å•Ÿå‹•æ”å½±æ©Ÿ
async function startCamera() {
    try {
        const constraints = {
            video: {
                width: 1280,
                height: 720
            }
        };
        
        const stream = await navigator.mediaDevices.getUserMedia(constraints);
        video.srcObject = stream;
        video.addEventListener('loadeddata', predictWebcam);
        webcamRunning = true;
        setStatus("ç³»çµ±é‹ä½œä¸­");
    } catch (error) {
        setStatus(`æ”å½±æ©ŸéŒ¯èª¤: ${error.message}`);
        console.error(error);
    }
}

// é æ¸¬èˆ‡ç¹ªè£½
async function predictWebcam() {
    canvasElement.width = video.videoWidth;
    canvasElement.height = video.videoHeight;
    
    try {
        if (lastVideoTime !== video.currentTime) {
            lastVideoTime = video.currentTime;
            results = faceLandmarker.detectForVideo(video, performance.now());
        }

        canvasCtx.clearRect(0, 0, canvasElement.width, canvasElement.height);
        
        if (results.faceLandmarks) {
            const drawingUtils = new DrawingUtils(canvasCtx);
            
            for (const landmarks of results.faceLandmarks) {
                // ç¹ªè£½çœ¼ç›
                const leftEye = landmarks[159];
                const rightEye = landmarks[386];
                
                // ç¹ªè£½ç…è›‹çœ¼ç›
                drawEmoji("ğŸ³", leftEye, 150);
                drawEmoji("ğŸ³", rightEye, 150);

                // ä¿®æ­£ï¼šä½¿ç”¨æ›´æº–ç¢ºçš„å˜´å·´ä¸Šä¸‹é»
                const upperLip = landmarks[0];  // ä¸Šå”‡ä¸­é»
                const lowerLip = landmarks[17]; // ä¸‹å”‡ä¸­é»
                
                // è¨ˆç®—å˜´å·´é–‹åˆçš„è·é›¢
                const mouthDistance = Math.abs(upperLip.y - lowerLip.y);
                // èª¿æ•´é–¾å€¼ç‚ºæ›´å°çš„å€¼
                const mouthOpen = mouthDistance > 0.03;

                // é™¤éŒ¯ç”¨ï¼šåœ¨æ§åˆ¶å°é¡¯ç¤ºè·é›¢
                console.log("Mouth distance:", mouthDistance);

                if (mouthOpen) {
                    const now = performance.now();
                    if (now - lastStarTime > STAR_INTERVAL) {
                        // è¨ˆç®—å˜´å·´ä¸­å¿ƒé»
                        const mouthX = ((upperLip.x + lowerLip.x) / 2) * canvasElement.width;
                        const mouthY = ((upperLip.y + lowerLip.y) / 2) * canvasElement.height;
                        
                        // å‰µå»ºæ–°æ˜Ÿæ˜Ÿ
                        stars.push(new Star(mouthX, mouthY));
                        lastStarTime = now;
                        
                        // é™¤éŒ¯ç”¨ï¼šé¡¯ç¤ºæ˜Ÿæ˜Ÿå‰µå»º
                        console.log("Star created at:", mouthX, mouthY);
                    }
                }
            }
        }

        // æ›´æ–°æ˜Ÿæ˜Ÿ
        stars = stars.filter(star => {
            const alive = star.update();
            if (!alive) {
                star.remove();
            }
            return alive;
        });

    } catch (error) {
        setStatus(`åµæ¸¬éŒ¯èª¤: ${error.message}`);
        console.error(error);
    }

    if (webcamRunning) {
        window.requestAnimationFrame(predictWebcam);
    }
}

// ç¹ªè£½ emoji çš„è¼”åŠ©å‡½æ•¸
function drawEmoji(emoji, position, size) {
    const x = position.x * canvasElement.width;
    const y = position.y * canvasElement.height;
    
    canvasCtx.font = `${size}px Arial`;
    canvasCtx.textAlign = 'center';
    canvasCtx.textBaseline = 'middle';
    canvasCtx.fillText(emoji, x, y);
}

// å•Ÿå‹•ç¨‹å¼
initializeFaceLandmarker();
</script>

</body>
</html>